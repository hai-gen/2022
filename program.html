---
title: Program
subtitle: Keynote speakers, papers, and demos
layout: page
show_sidebar: false
---

<h1>Keynote Speaker</h1>

<div class="columns box">
    <div class="column is-6">
        <div class="column">
            {% include image-modal.html ratio="is-16by9" link="../img/sarah.png" alt="Sarah Schwettmann" %}
        </div>
        <div class="column">
            <p class="title">Sarah Schwettmann</p>
            <p class="subtitle"><a href="http://www.cogconfluence.com">http://www.cogconfluence.com</a></p>
            <h3>AI Models as a Shared Creative Resource</h3>
            <h4><em>The Human Use of New Machines</em></h4>
            <p>This talk is born out of a series of collaborations with deep generative models that capture human
                creativity at different scales. These tools hold a beautiful promise: within reach is the ability for
                anyone to collaborate with executable models of individual and collective cultural history, on a
                timeline allowing experimentation and rapid evolution in the present. To fully realize this future, we
                need modes of multiplexing creation, across platforms and processes, that are understood as a
                magnification of creative identity rather than a dilution. How can we establish infrastructure and norms
                around contributing to shared models, and around the idea of models as a shared resource? At their best,
                such models both facilitate co-creation and provide a context for interpreting the structure underlying
                human creativity and perception &mdash; a feedback loop befitting a 21st century articulation of
                iterative creativity.</p>
            <h4>Bio</h4>
            <p>Sarah Schwettmann is a neuroscientist and machine learning researcher at MIT CSAIL. She completed her PhD
                in Brain and Cognitive Sciences at MIT, where she was an NSF Fellow. Her work investigates generalizable
                representations for vision in biological and artificial neural networks. She is broadly interested in
                creativity underlying the human relationship to the world: from the brain's fundamentally constructive
                role in sensory perception to the explicit creation of experiential worlds in art. Sarah designed and
                teaches MIT's first course on Vision in Art and Neuroscience, and leads research efforts in the MIT
                Museum Studio.</p>
            <p>Sarah has translated her work into a wide range of collaborations, including with The Metropolitan Museum
                of Art, MIT Open Learning, Microsoft Research, the Knowledge Futures Group, MIT Quest for Intelligence,
                MFA Boston, Harvard's Berkman Klein Center for Internet and Society, and the MIT Museum. Prior to MIT
                she lived in Houston, Texas, where her work was in theoretical neuroscience.</p>
        </div>
    </div>
</div>

<h1>Workshop Program</h1>

<p>Times are primarily listed in Eastern Daylight Time (UTC-4). Additional times are shown for Pacific Daylight Time
    (UTC-7), Central European Time (UTC+1), and Australian Eastern Daylight Time (UTC+11).</p>

<div class="columns box">
    <table class="table is-fullwidth">
        <thead style="text-align: left;">
            <th style="min-width: 140px;">Time</th>
            <th>Activity</th>
        </thead>
        <tbody>
            <tr>
                <td>10am EDT
                    <br /><span style="font-size: 0.8em; color: #aaa">7am PDT</span>
                    <br /><span style="font-size: 0.8em; color: #aaa">3pm CET</span>
                    <br /><span style="font-size: 0.8em; color: #aaa">1am AEDT</span>
                </td>
                <td>
                    <p><strong>Kickoff</strong></p>
                    <p>Welcoming remarks from Justin Weisz &amp; Werner Geyer</p>
                </td>
            </tr>
            <tr>
                <td>10:15am EDT
                    <br /><span style="font-size: 0.8em; color: #aaa">7:15am PDT</span>
                    <br /><span style="font-size: 0.8em; color: #aaa">3:15pm CET</span>
                    <br /><span style="font-size: 0.8em; color: #aaa">1:15am AEDT</span>
                </td>
                <td>
                    <p><strong>Keynote: Sarah Schwettmann &mdash; AI Models as a Shared Creative Resource</strong></p>
                    <p>Introduction by Hendrik Strobelt</p>
                </td>
            </tr>
            <tr>
                <td>11:15am EDT
                    <br /><span style="font-size: 0.8em; color: #aaa">8:15am PDT</span>
                    <br /><span style="font-size: 0.8em; color: #aaa">4:15pm CET</span>
                    <br /><span style="font-size: 0.8em; color: #aaa">2:15am AEDT</span>
                </td>
                <td>
                    <p><strong>Break &amp; Open Discussion</strong></p>
                </td>
            </tr>
            <tr>
                <td>11:20am EDT
                    <br /><span style="font-size: 0.8em; color: #aaa">8:20am PDT</span>
                    <br /><span style="font-size: 0.8em; color: #aaa">4:20pm CET</span>
                    <br /><span style="font-size: 0.8em; color: #aaa">2:20am AEDT</span>
                </td>
                <td>
                    <p><strong>Session 1: Interacting with Generative AI</strong></p>
                    <p>Chair: Lydia Chilton</p>
                    <ul>
                        <li>Imke Grabe, Miguel Gonz√°lez-Duque, Sebastian Risi and Jichen Zhu. <a href="../papers/paper-HAIGEN-GrabeImke.pdf">Towards A Framework for Human-AI Interaction Patterns in Co-Creative GAN Applications</a></li>
                        <li>John Joon Young Chung, Minsuk Chang and Eytan Adar. <a href="../papers/paper-HAIGEN-ChungJohn.pdf">Gestural Inputs as Control Interaction for Generative Human-AI Co-Creation</a></li>
                        <li>Max Kreminski, Isaac Karth, Michael Mateas and Noah Wardrip-Fruin. <a href="../papers/paper-HAIGEN-KreminskiMax.pdf">Evaluating Mixed-Initiative Creative Interfaces via Expressive Range Coverage Analysis</a></li>
                        <li>Stephanie Houde, Steven Ross, Michael Muller, Mayank Agarwal, Fernando Martinez, John Richards, Kartik Talamadupula and Justin D. Weisz. <a href="../papers/paper-HAIGEN-HoudeStephanie.pdf">Opportunities for Generative AI in UX Modernization</a></li>
                    </ul>
                </td>
            </tr>
            <tr>
                <td>12:20pm EDT
                    <br /><span style="font-size: 0.8em; color: #aaa">9:20am PDT</span>
                    <br /><span style="font-size: 0.8em; color: #aaa">5:20pm CET</span>
                    <br /><span style="font-size: 0.8em; color: #aaa">3:20pm AEDT</span>
                </td>
                <td>
                    <p><strong>Break &amp; Open Discussion</strong></p>
                </td>
            </tr>
            <tr>
                <td>12:25pm EDT
                    <br /><span style="font-size: 0.8em; color: #aaa">9:25am PDT</span>
                    <br /><span style="font-size: 0.8em; color: #aaa">5:25pm CET</span>
                    <br /><span style="font-size: 0.8em; color: #aaa">3:25am AEDT</span>
                </td>
                <td>
                    <p><strong>Session 2: Text, Code, and Music</strong></p>
                    <p>Chair: David Bau</p>
                    <ul>
                        <li>Daijin Yang, Yanpeng Zhou, Zhiyuan Zhang, Toby Jia-Jun Li and Ray LC. <a href="../papers/paper-HAIGEN-YangDaijin.pdf">AI as an Active Writer: Interaction strategies with generated text in human-AI collaborative fiction writing</a></li>
                        <li>Michael Muller, Steven Ross, Stephanie Houde, Mayank Agarwal, Fernando Martinez, John Richards, Kartik Talamadupula and Justin D. Weisz. <a href="../papers/paper-HAIGEN-MullerMichael.pdf">Drinking Chai with Your (AI) Programming Partner: A Design Fiction about Generative AI for Software Engineering</a></li>
                        <li>Halley Young, Vincent Dumoulin, Pablo S. Castro, Jesse Engel and Cheng-Zhi Anna Huang. <a href="../papers/paper-HAIGEN-YoungHalley.pdf">Compositional Steering of Music Transformers</a></li>
                        <li>Charles Patrick Martin. <a href="../papers/paper-HAIGEN-MartinCharles.pdf">Performing with a Generative Electronic Music Controller</a></li>
                    </ul>
                </td>
            </tr>
            <tr>
                <td>1:25pm EDT
                    <br /><span style="font-size: 0.8em; color: #aaa">10:25am PDT</span>
                    <br /><span style="font-size: 0.8em; color: #aaa">6:25pm CET</span>
                    <br /><span style="font-size: 0.8em; color: #aaa">4:25am AEDT</span>
                </td>
                <td>
                    <p><strong>Discussion</strong></p>
                    <p>Chair: Mary Lou Maher</p>
                </td>
            </tr>
            <tr>
                <td>2pm EDT
                    <br /><span style="font-size: 0.8em; color: #aaa">11am PDT</span>
                    <br /><span style="font-size: 0.8em; color: #aaa">7pm CET</span>
                    <br /><span style="font-size: 0.8em; color: #aaa">5am AEDT</span>
                </td>
                <td>
                    <p><strong>Workshop End</strong></p>
                </td>
            </tr>
        </tbody>
    </table>
</div>
